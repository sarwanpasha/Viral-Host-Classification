{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "# import seaborn as sns\n",
    "import os.path as path\n",
    "import os\n",
    "# import matplotlib\n",
    "# import matplotlib.font_manager\n",
    "# import matplotlib.pyplot as plt # graphs plotting\n",
    "# import Bio\n",
    "from Bio import SeqIO # some BioPython that will come in handy\n",
    "#matplotlib inline\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# from matplotlib import rc\n",
    "# # for Arial typefont\n",
    "# matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "## for LaTeX typefont\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "# matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "## for another LaTeX typefont\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.load(\"E:/GISAID/non_humans_spike_sequences.npy\",allow_pickle=True)\n",
    "attributes = np.load(\"E:/GISAID/non_humans_attributes.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_names = []\n",
    "for i in range(len(attributes)):\n",
    "    temp = attributes[i]\n",
    "    host_names.append(temp[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmers(sequence, ksize):\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - ksize + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + ksize]\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2210\n",
      "1 / 2210\n",
      "2 / 2210\n",
      "3 / 2210\n",
      "4 / 2210\n",
      "5 / 2210\n",
      "6 / 2210\n",
      "7 / 2210\n",
      "8 / 2210\n",
      "9 / 2210\n",
      "10 / 2210\n",
      "11 / 2210\n",
      "12 / 2210\n",
      "13 / 2210\n",
      "14 / 2210\n",
      "15 / 2210\n",
      "16 / 2210\n",
      "17 / 2210\n",
      "18 / 2210\n",
      "19 / 2210\n",
      "20 / 2210\n",
      "21 / 2210\n",
      "22 / 2210\n",
      "23 / 2210\n",
      "24 / 2210\n",
      "25 / 2210\n",
      "26 / 2210\n",
      "27 / 2210\n",
      "28 / 2210\n",
      "29 / 2210\n",
      "30 / 2210\n",
      "31 / 2210\n",
      "32 / 2210\n",
      "33 / 2210\n",
      "34 / 2210\n",
      "35 / 2210\n",
      "36 / 2210\n",
      "37 / 2210\n",
      "38 / 2210\n",
      "39 / 2210\n",
      "40 / 2210\n",
      "41 / 2210\n",
      "42 / 2210\n",
      "43 / 2210\n",
      "44 / 2210\n",
      "45 / 2210\n",
      "46 / 2210\n",
      "47 / 2210\n",
      "48 / 2210\n",
      "49 / 2210\n",
      "50 / 2210\n",
      "51 / 2210\n",
      "52 / 2210\n",
      "53 / 2210\n",
      "54 / 2210\n",
      "55 / 2210\n",
      "56 / 2210\n",
      "57 / 2210\n",
      "58 / 2210\n",
      "59 / 2210\n",
      "60 / 2210\n",
      "61 / 2210\n",
      "62 / 2210\n",
      "63 / 2210\n",
      "64 / 2210\n",
      "65 / 2210\n",
      "66 / 2210\n",
      "67 / 2210\n",
      "68 / 2210\n",
      "69 / 2210\n",
      "70 / 2210\n",
      "71 / 2210\n",
      "72 / 2210\n",
      "73 / 2210\n",
      "74 / 2210\n",
      "75 / 2210\n",
      "76 / 2210\n",
      "77 / 2210\n",
      "78 / 2210\n",
      "79 / 2210\n",
      "80 / 2210\n",
      "81 / 2210\n",
      "82 / 2210\n",
      "83 / 2210\n",
      "84 / 2210\n",
      "85 / 2210\n",
      "86 / 2210\n",
      "87 / 2210\n",
      "88 / 2210\n",
      "89 / 2210\n",
      "90 / 2210\n",
      "91 / 2210\n",
      "92 / 2210\n",
      "93 / 2210\n",
      "94 / 2210\n",
      "95 / 2210\n",
      "96 / 2210\n",
      "97 / 2210\n",
      "98 / 2210\n",
      "99 / 2210\n",
      "100 / 2210\n",
      "101 / 2210\n",
      "102 / 2210\n",
      "103 / 2210\n",
      "104 / 2210\n",
      "105 / 2210\n",
      "106 / 2210\n",
      "107 / 2210\n",
      "108 / 2210\n",
      "109 / 2210\n",
      "110 / 2210\n",
      "111 / 2210\n",
      "112 / 2210\n",
      "113 / 2210\n",
      "114 / 2210\n",
      "115 / 2210\n",
      "116 / 2210\n",
      "117 / 2210\n",
      "118 / 2210\n",
      "119 / 2210\n",
      "120 / 2210\n",
      "121 / 2210\n",
      "122 / 2210\n",
      "123 / 2210\n",
      "124 / 2210\n",
      "125 / 2210\n",
      "126 / 2210\n",
      "127 / 2210\n",
      "128 / 2210\n",
      "129 / 2210\n",
      "130 / 2210\n",
      "131 / 2210\n",
      "132 / 2210\n",
      "133 / 2210\n",
      "134 / 2210\n",
      "135 / 2210\n",
      "136 / 2210\n",
      "137 / 2210\n",
      "138 / 2210\n",
      "139 / 2210\n",
      "140 / 2210\n",
      "141 / 2210\n",
      "142 / 2210\n",
      "143 / 2210\n",
      "144 / 2210\n",
      "145 / 2210\n",
      "146 / 2210\n",
      "147 / 2210\n",
      "148 / 2210\n",
      "149 / 2210\n",
      "150 / 2210\n",
      "151 / 2210\n",
      "152 / 2210\n",
      "153 / 2210\n",
      "154 / 2210\n",
      "155 / 2210\n",
      "156 / 2210\n",
      "157 / 2210\n",
      "158 / 2210\n",
      "159 / 2210\n",
      "160 / 2210\n",
      "161 / 2210\n",
      "162 / 2210\n",
      "163 / 2210\n",
      "164 / 2210\n",
      "165 / 2210\n",
      "166 / 2210\n",
      "167 / 2210\n",
      "168 / 2210\n",
      "169 / 2210\n",
      "170 / 2210\n",
      "171 / 2210\n",
      "172 / 2210\n",
      "173 / 2210\n",
      "174 / 2210\n",
      "175 / 2210\n",
      "176 / 2210\n",
      "177 / 2210\n",
      "178 / 2210\n",
      "179 / 2210\n",
      "180 / 2210\n",
      "181 / 2210\n",
      "182 / 2210\n",
      "183 / 2210\n",
      "184 / 2210\n",
      "185 / 2210\n",
      "186 / 2210\n",
      "187 / 2210\n",
      "188 / 2210\n",
      "189 / 2210\n",
      "190 / 2210\n",
      "191 / 2210\n",
      "192 / 2210\n",
      "193 / 2210\n",
      "194 / 2210\n",
      "195 / 2210\n",
      "196 / 2210\n",
      "197 / 2210\n",
      "198 / 2210\n",
      "199 / 2210\n",
      "200 / 2210\n",
      "201 / 2210\n",
      "202 / 2210\n",
      "203 / 2210\n",
      "204 / 2210\n",
      "205 / 2210\n",
      "206 / 2210\n",
      "207 / 2210\n",
      "208 / 2210\n",
      "209 / 2210\n",
      "210 / 2210\n",
      "211 / 2210\n",
      "212 / 2210\n",
      "213 / 2210\n",
      "214 / 2210\n",
      "215 / 2210\n",
      "216 / 2210\n",
      "217 / 2210\n",
      "218 / 2210\n",
      "219 / 2210\n",
      "220 / 2210\n",
      "221 / 2210\n",
      "222 / 2210\n",
      "223 / 2210\n",
      "224 / 2210\n",
      "225 / 2210\n",
      "226 / 2210\n",
      "227 / 2210\n",
      "228 / 2210\n",
      "229 / 2210\n",
      "230 / 2210\n",
      "231 / 2210\n",
      "232 / 2210\n",
      "233 / 2210\n",
      "234 / 2210\n",
      "235 / 2210\n",
      "236 / 2210\n",
      "237 / 2210\n",
      "238 / 2210\n",
      "239 / 2210\n",
      "240 / 2210\n",
      "241 / 2210\n",
      "242 / 2210\n",
      "243 / 2210\n",
      "244 / 2210\n",
      "245 / 2210\n",
      "246 / 2210\n",
      "247 / 2210\n",
      "248 / 2210\n",
      "249 / 2210\n",
      "250 / 2210\n",
      "251 / 2210\n",
      "252 / 2210\n",
      "253 / 2210\n",
      "254 / 2210\n",
      "255 / 2210\n",
      "256 / 2210\n",
      "257 / 2210\n",
      "258 / 2210\n",
      "259 / 2210\n",
      "260 / 2210\n",
      "261 / 2210\n",
      "262 / 2210\n",
      "263 / 2210\n",
      "264 / 2210\n",
      "265 / 2210\n",
      "266 / 2210\n",
      "267 / 2210\n",
      "268 / 2210\n",
      "269 / 2210\n",
      "270 / 2210\n",
      "271 / 2210\n",
      "272 / 2210\n",
      "273 / 2210\n",
      "274 / 2210\n",
      "275 / 2210\n",
      "276 / 2210\n",
      "277 / 2210\n",
      "278 / 2210\n",
      "279 / 2210\n",
      "280 / 2210\n",
      "281 / 2210\n",
      "282 / 2210\n",
      "283 / 2210\n",
      "284 / 2210\n",
      "285 / 2210\n",
      "286 / 2210\n",
      "287 / 2210\n",
      "288 / 2210\n",
      "289 / 2210\n",
      "290 / 2210\n",
      "291 / 2210\n",
      "292 / 2210\n",
      "293 / 2210\n",
      "294 / 2210\n",
      "295 / 2210\n",
      "296 / 2210\n",
      "297 / 2210\n",
      "298 / 2210\n",
      "299 / 2210\n",
      "300 / 2210\n",
      "301 / 2210\n",
      "302 / 2210\n",
      "303 / 2210\n",
      "304 / 2210\n",
      "305 / 2210\n",
      "306 / 2210\n",
      "307 / 2210\n",
      "308 / 2210\n",
      "309 / 2210\n",
      "310 / 2210\n",
      "311 / 2210\n",
      "312 / 2210\n",
      "313 / 2210\n",
      "314 / 2210\n",
      "315 / 2210\n",
      "316 / 2210\n",
      "317 / 2210\n",
      "318 / 2210\n",
      "319 / 2210\n",
      "320 / 2210\n",
      "321 / 2210\n",
      "322 / 2210\n",
      "323 / 2210\n",
      "324 / 2210\n",
      "325 / 2210\n",
      "326 / 2210\n",
      "327 / 2210\n",
      "328 / 2210\n",
      "329 / 2210\n",
      "330 / 2210\n",
      "331 / 2210\n",
      "332 / 2210\n",
      "333 / 2210\n",
      "334 / 2210\n",
      "335 / 2210\n",
      "336 / 2210\n",
      "337 / 2210\n",
      "338 / 2210\n",
      "339 / 2210\n",
      "340 / 2210\n",
      "341 / 2210\n",
      "342 / 2210\n",
      "343 / 2210\n",
      "344 / 2210\n",
      "345 / 2210\n",
      "346 / 2210\n",
      "347 / 2210\n",
      "348 / 2210\n",
      "349 / 2210\n",
      "350 / 2210\n",
      "351 / 2210\n",
      "352 / 2210\n",
      "353 / 2210\n",
      "354 / 2210\n",
      "355 / 2210\n",
      "356 / 2210\n",
      "357 / 2210\n",
      "358 / 2210\n",
      "359 / 2210\n",
      "360 / 2210\n",
      "361 / 2210\n",
      "362 / 2210\n",
      "363 / 2210\n",
      "364 / 2210\n",
      "365 / 2210\n",
      "366 / 2210\n",
      "367 / 2210\n",
      "368 / 2210\n",
      "369 / 2210\n",
      "370 / 2210\n",
      "371 / 2210\n",
      "372 / 2210\n",
      "373 / 2210\n",
      "374 / 2210\n",
      "375 / 2210\n",
      "376 / 2210\n",
      "377 / 2210\n",
      "378 / 2210\n",
      "379 / 2210\n",
      "380 / 2210\n",
      "381 / 2210\n",
      "382 / 2210\n",
      "383 / 2210\n",
      "384 / 2210\n",
      "385 / 2210\n",
      "386 / 2210\n",
      "387 / 2210\n",
      "388 / 2210\n",
      "389 / 2210\n",
      "390 / 2210\n",
      "391 / 2210\n",
      "392 / 2210\n",
      "393 / 2210\n",
      "394 / 2210\n",
      "395 / 2210\n",
      "396 / 2210\n",
      "397 / 2210\n",
      "398 / 2210\n",
      "399 / 2210\n",
      "400 / 2210\n",
      "401 / 2210\n",
      "402 / 2210\n",
      "403 / 2210\n",
      "404 / 2210\n",
      "405 / 2210\n",
      "406 / 2210\n",
      "407 / 2210\n",
      "408 / 2210\n",
      "409 / 2210\n",
      "410 / 2210\n",
      "411 / 2210\n",
      "412 / 2210\n",
      "413 / 2210\n",
      "414 / 2210\n",
      "415 / 2210\n",
      "416 / 2210\n",
      "417 / 2210\n",
      "418 / 2210\n",
      "419 / 2210\n",
      "420 / 2210\n",
      "421 / 2210\n",
      "422 / 2210\n",
      "423 / 2210\n",
      "424 / 2210\n",
      "425 / 2210\n",
      "426 / 2210\n",
      "427 / 2210\n",
      "428 / 2210\n",
      "429 / 2210\n",
      "430 / 2210\n",
      "431 / 2210\n",
      "432 / 2210\n",
      "433 / 2210\n",
      "434 / 2210\n",
      "435 / 2210\n",
      "436 / 2210\n",
      "437 / 2210\n",
      "438 / 2210\n",
      "439 / 2210\n",
      "440 / 2210\n",
      "441 / 2210\n",
      "442 / 2210\n",
      "443 / 2210\n",
      "444 / 2210\n",
      "445 / 2210\n",
      "446 / 2210\n",
      "447 / 2210\n",
      "448 / 2210\n",
      "449 / 2210\n",
      "450 / 2210\n",
      "451 / 2210\n",
      "452 / 2210\n",
      "453 / 2210\n",
      "454 / 2210\n",
      "455 / 2210\n",
      "456 / 2210\n",
      "457 / 2210\n",
      "458 / 2210\n",
      "459 / 2210\n",
      "460 / 2210\n",
      "461 / 2210\n",
      "462 / 2210\n",
      "463 / 2210\n",
      "464 / 2210\n",
      "465 / 2210\n",
      "466 / 2210\n",
      "467 / 2210\n",
      "468 / 2210\n",
      "469 / 2210\n",
      "470 / 2210\n",
      "471 / 2210\n",
      "472 / 2210\n",
      "473 / 2210\n",
      "474 / 2210\n",
      "475 / 2210\n",
      "476 / 2210\n",
      "477 / 2210\n",
      "478 / 2210\n",
      "479 / 2210\n",
      "480 / 2210\n",
      "481 / 2210\n",
      "482 / 2210\n",
      "483 / 2210\n",
      "484 / 2210\n",
      "485 / 2210\n",
      "486 / 2210\n",
      "487 / 2210\n",
      "488 / 2210\n",
      "489 / 2210\n",
      "490 / 2210\n",
      "491 / 2210\n",
      "492 / 2210\n",
      "493 / 2210\n",
      "494 / 2210\n",
      "495 / 2210\n",
      "496 / 2210\n",
      "497 / 2210\n",
      "498 / 2210\n",
      "499 / 2210\n",
      "500 / 2210\n",
      "501 / 2210\n",
      "502 / 2210\n",
      "503 / 2210\n",
      "504 / 2210\n",
      "505 / 2210\n",
      "506 / 2210\n",
      "507 / 2210\n",
      "508 / 2210\n",
      "509 / 2210\n",
      "510 / 2210\n",
      "511 / 2210\n",
      "512 / 2210\n",
      "513 / 2210\n",
      "514 / 2210\n",
      "515 / 2210\n",
      "516 / 2210\n",
      "517 / 2210\n",
      "518 / 2210\n",
      "519 / 2210\n",
      "520 / 2210\n",
      "521 / 2210\n",
      "522 / 2210\n",
      "523 / 2210\n",
      "524 / 2210\n",
      "525 / 2210\n",
      "526 / 2210\n",
      "527 / 2210\n",
      "528 / 2210\n",
      "529 / 2210\n",
      "530 / 2210\n",
      "531 / 2210\n",
      "532 / 2210\n",
      "533 / 2210\n",
      "534 / 2210\n",
      "535 / 2210\n",
      "536 / 2210\n",
      "537 / 2210\n",
      "538 / 2210\n",
      "539 / 2210\n",
      "540 / 2210\n",
      "541 / 2210\n",
      "542 / 2210\n",
      "543 / 2210\n",
      "544 / 2210\n",
      "545 / 2210\n",
      "546 / 2210\n",
      "547 / 2210\n",
      "548 / 2210\n",
      "549 / 2210\n",
      "550 / 2210\n",
      "551 / 2210\n",
      "552 / 2210\n",
      "553 / 2210\n",
      "554 / 2210\n",
      "555 / 2210\n",
      "556 / 2210\n",
      "557 / 2210\n",
      "558 / 2210\n",
      "559 / 2210\n",
      "560 / 2210\n",
      "561 / 2210\n",
      "562 / 2210\n",
      "563 / 2210\n",
      "564 / 2210\n",
      "565 / 2210\n",
      "566 / 2210\n",
      "567 / 2210\n",
      "568 / 2210\n",
      "569 / 2210\n",
      "570 / 2210\n",
      "571 / 2210\n",
      "572 / 2210\n",
      "573 / 2210\n",
      "574 / 2210\n",
      "575 / 2210\n",
      "576 / 2210\n",
      "577 / 2210\n",
      "578 / 2210\n",
      "579 / 2210\n",
      "580 / 2210\n",
      "581 / 2210\n",
      "582 / 2210\n",
      "583 / 2210\n",
      "584 / 2210\n",
      "585 / 2210\n",
      "586 / 2210\n",
      "587 / 2210\n",
      "588 / 2210\n",
      "589 / 2210\n",
      "590 / 2210\n",
      "591 / 2210\n",
      "592 / 2210\n",
      "593 / 2210\n",
      "594 / 2210\n",
      "595 / 2210\n",
      "596 / 2210\n",
      "597 / 2210\n",
      "598 / 2210\n",
      "599 / 2210\n",
      "600 / 2210\n",
      "601 / 2210\n",
      "602 / 2210\n",
      "603 / 2210\n",
      "604 / 2210\n",
      "605 / 2210\n",
      "606 / 2210\n",
      "607 / 2210\n",
      "608 / 2210\n",
      "609 / 2210\n",
      "610 / 2210\n",
      "611 / 2210\n",
      "612 / 2210\n",
      "613 / 2210\n",
      "614 / 2210\n",
      "615 / 2210\n",
      "616 / 2210\n",
      "617 / 2210\n",
      "618 / 2210\n",
      "619 / 2210\n",
      "620 / 2210\n",
      "621 / 2210\n",
      "622 / 2210\n",
      "623 / 2210\n",
      "624 / 2210\n",
      "625 / 2210\n",
      "626 / 2210\n",
      "627 / 2210\n",
      "628 / 2210\n",
      "629 / 2210\n",
      "630 / 2210\n",
      "631 / 2210\n",
      "632 / 2210\n",
      "633 / 2210\n",
      "634 / 2210\n",
      "635 / 2210\n",
      "636 / 2210\n",
      "637 / 2210\n",
      "638 / 2210\n",
      "639 / 2210\n",
      "640 / 2210\n",
      "641 / 2210\n",
      "642 / 2210\n",
      "643 / 2210\n",
      "644 / 2210\n",
      "645 / 2210\n",
      "646 / 2210\n",
      "647 / 2210\n",
      "648 / 2210\n",
      "649 / 2210\n",
      "650 / 2210\n",
      "651 / 2210\n",
      "652 / 2210\n",
      "653 / 2210\n",
      "654 / 2210\n",
      "655 / 2210\n",
      "656 / 2210\n",
      "657 / 2210\n",
      "658 / 2210\n",
      "659 / 2210\n",
      "660 / 2210\n",
      "661 / 2210\n",
      "662 / 2210\n",
      "663 / 2210\n",
      "664 / 2210\n",
      "665 / 2210\n",
      "666 / 2210\n",
      "667 / 2210\n",
      "668 / 2210\n",
      "669 / 2210\n",
      "670 / 2210\n",
      "671 / 2210\n",
      "672 / 2210\n",
      "673 / 2210\n",
      "674 / 2210\n",
      "675 / 2210\n",
      "676 / 2210\n",
      "677 / 2210\n",
      "678 / 2210\n",
      "679 / 2210\n",
      "680 / 2210\n",
      "681 / 2210\n",
      "682 / 2210\n",
      "683 / 2210\n",
      "684 / 2210\n",
      "685 / 2210\n",
      "686 / 2210\n",
      "687 / 2210\n",
      "688 / 2210\n",
      "689 / 2210\n",
      "690 / 2210\n",
      "691 / 2210\n",
      "692 / 2210\n",
      "693 / 2210\n",
      "694 / 2210\n",
      "695 / 2210\n",
      "696 / 2210\n",
      "697 / 2210\n",
      "698 / 2210\n",
      "699 / 2210\n",
      "700 / 2210\n",
      "701 / 2210\n",
      "702 / 2210\n",
      "703 / 2210\n",
      "704 / 2210\n",
      "705 / 2210\n",
      "706 / 2210\n",
      "707 / 2210\n",
      "708 / 2210\n",
      "709 / 2210\n",
      "710 / 2210\n",
      "711 / 2210\n",
      "712 / 2210\n",
      "713 / 2210\n",
      "714 / 2210\n",
      "715 / 2210\n",
      "716 / 2210\n",
      "717 / 2210\n",
      "718 / 2210\n",
      "719 / 2210\n",
      "720 / 2210\n",
      "721 / 2210\n",
      "722 / 2210\n",
      "723 / 2210\n",
      "724 / 2210\n",
      "725 / 2210\n",
      "726 / 2210\n",
      "727 / 2210\n",
      "728 / 2210\n",
      "729 / 2210\n",
      "730 / 2210\n",
      "731 / 2210\n",
      "732 / 2210\n",
      "733 / 2210\n",
      "734 / 2210\n",
      "735 / 2210\n",
      "736 / 2210\n",
      "737 / 2210\n",
      "738 / 2210\n",
      "739 / 2210\n",
      "740 / 2210\n",
      "741 / 2210\n",
      "742 / 2210\n",
      "743 / 2210\n",
      "744 / 2210\n",
      "745 / 2210\n",
      "746 / 2210\n",
      "747 / 2210\n",
      "748 / 2210\n",
      "749 / 2210\n",
      "750 / 2210\n",
      "751 / 2210\n",
      "752 / 2210\n",
      "753 / 2210\n",
      "754 / 2210\n",
      "755 / 2210\n",
      "756 / 2210\n",
      "757 / 2210\n",
      "758 / 2210\n",
      "759 / 2210\n",
      "760 / 2210\n",
      "761 / 2210\n",
      "762 / 2210\n",
      "763 / 2210\n",
      "764 / 2210\n",
      "765 / 2210\n",
      "766 / 2210\n",
      "767 / 2210\n",
      "768 / 2210\n",
      "769 / 2210\n",
      "770 / 2210\n",
      "771 / 2210\n",
      "772 / 2210\n",
      "773 / 2210\n",
      "774 / 2210\n",
      "775 / 2210\n",
      "776 / 2210\n",
      "777 / 2210\n",
      "778 / 2210\n",
      "779 / 2210\n",
      "780 / 2210\n",
      "781 / 2210\n",
      "782 / 2210\n",
      "783 / 2210\n",
      "784 / 2210\n",
      "785 / 2210\n",
      "786 / 2210\n",
      "787 / 2210\n",
      "788 / 2210\n",
      "789 / 2210\n",
      "790 / 2210\n",
      "791 / 2210\n",
      "792 / 2210\n",
      "793 / 2210\n",
      "794 / 2210\n",
      "795 / 2210\n",
      "796 / 2210\n",
      "797 / 2210\n",
      "798 / 2210\n",
      "799 / 2210\n",
      "800 / 2210\n",
      "801 / 2210\n",
      "802 / 2210\n",
      "803 / 2210\n",
      "804 / 2210\n",
      "805 / 2210\n",
      "806 / 2210\n",
      "807 / 2210\n",
      "808 / 2210\n",
      "809 / 2210\n",
      "810 / 2210\n",
      "811 / 2210\n",
      "812 / 2210\n",
      "813 / 2210\n",
      "814 / 2210\n",
      "815 / 2210\n",
      "816 / 2210\n",
      "817 / 2210\n",
      "818 / 2210\n",
      "819 / 2210\n",
      "820 / 2210\n",
      "821 / 2210\n",
      "822 / 2210\n",
      "823 / 2210\n",
      "824 / 2210\n",
      "825 / 2210\n",
      "826 / 2210\n",
      "827 / 2210\n",
      "828 / 2210\n",
      "829 / 2210\n",
      "830 / 2210\n",
      "831 / 2210\n",
      "832 / 2210\n",
      "833 / 2210\n",
      "834 / 2210\n",
      "835 / 2210\n",
      "836 / 2210\n",
      "837 / 2210\n",
      "838 / 2210\n",
      "839 / 2210\n",
      "840 / 2210\n",
      "841 / 2210\n",
      "842 / 2210\n",
      "843 / 2210\n",
      "844 / 2210\n",
      "845 / 2210\n",
      "846 / 2210\n",
      "847 / 2210\n",
      "848 / 2210\n",
      "849 / 2210\n",
      "850 / 2210\n",
      "851 / 2210\n",
      "852 / 2210\n",
      "853 / 2210\n",
      "854 / 2210\n",
      "855 / 2210\n",
      "856 / 2210\n",
      "857 / 2210\n",
      "858 / 2210\n",
      "859 / 2210\n",
      "860 / 2210\n",
      "861 / 2210\n",
      "862 / 2210\n",
      "863 / 2210\n",
      "864 / 2210\n",
      "865 / 2210\n",
      "866 / 2210\n",
      "867 / 2210\n",
      "868 / 2210\n",
      "869 / 2210\n",
      "870 / 2210\n",
      "871 / 2210\n",
      "872 / 2210\n",
      "873 / 2210\n",
      "874 / 2210\n",
      "875 / 2210\n",
      "876 / 2210\n",
      "877 / 2210\n",
      "878 / 2210\n",
      "879 / 2210\n",
      "880 / 2210\n",
      "881 / 2210\n",
      "882 / 2210\n",
      "883 / 2210\n",
      "884 / 2210\n",
      "885 / 2210\n",
      "886 / 2210\n",
      "887 / 2210\n",
      "888 / 2210\n",
      "889 / 2210\n",
      "890 / 2210\n",
      "891 / 2210\n",
      "892 / 2210\n",
      "893 / 2210\n",
      "894 / 2210\n",
      "895 / 2210\n",
      "896 / 2210\n",
      "897 / 2210\n",
      "898 / 2210\n",
      "899 / 2210\n",
      "900 / 2210\n",
      "901 / 2210\n",
      "902 / 2210\n",
      "903 / 2210\n",
      "904 / 2210\n",
      "905 / 2210\n",
      "906 / 2210\n",
      "907 / 2210\n",
      "908 / 2210\n",
      "909 / 2210\n",
      "910 / 2210\n",
      "911 / 2210\n",
      "912 / 2210\n",
      "913 / 2210\n",
      "914 / 2210\n",
      "915 / 2210\n",
      "916 / 2210\n",
      "917 / 2210\n",
      "918 / 2210\n",
      "919 / 2210\n",
      "920 / 2210\n",
      "921 / 2210\n",
      "922 / 2210\n",
      "923 / 2210\n",
      "924 / 2210\n",
      "925 / 2210\n",
      "926 / 2210\n",
      "927 / 2210\n",
      "928 / 2210\n",
      "929 / 2210\n",
      "930 / 2210\n",
      "931 / 2210\n",
      "932 / 2210\n",
      "933 / 2210\n",
      "934 / 2210\n",
      "935 / 2210\n",
      "936 / 2210\n",
      "937 / 2210\n",
      "938 / 2210\n",
      "939 / 2210\n",
      "940 / 2210\n",
      "941 / 2210\n",
      "942 / 2210\n",
      "943 / 2210\n",
      "944 / 2210\n",
      "945 / 2210\n",
      "946 / 2210\n",
      "947 / 2210\n",
      "948 / 2210\n",
      "949 / 2210\n",
      "950 / 2210\n",
      "951 / 2210\n",
      "952 / 2210\n",
      "953 / 2210\n",
      "954 / 2210\n",
      "955 / 2210\n",
      "956 / 2210\n",
      "957 / 2210\n",
      "958 / 2210\n",
      "959 / 2210\n",
      "960 / 2210\n",
      "961 / 2210\n",
      "962 / 2210\n",
      "963 / 2210\n",
      "964 / 2210\n",
      "965 / 2210\n",
      "966 / 2210\n",
      "967 / 2210\n",
      "968 / 2210\n",
      "969 / 2210\n",
      "970 / 2210\n",
      "971 / 2210\n",
      "972 / 2210\n",
      "973 / 2210\n",
      "974 / 2210\n",
      "975 / 2210\n",
      "976 / 2210\n",
      "977 / 2210\n",
      "978 / 2210\n",
      "979 / 2210\n",
      "980 / 2210\n",
      "981 / 2210\n",
      "982 / 2210\n",
      "983 / 2210\n",
      "984 / 2210\n",
      "985 / 2210\n",
      "986 / 2210\n",
      "987 / 2210\n",
      "988 / 2210\n",
      "989 / 2210\n",
      "990 / 2210\n",
      "991 / 2210\n",
      "992 / 2210\n",
      "993 / 2210\n",
      "994 / 2210\n",
      "995 / 2210\n",
      "996 / 2210\n",
      "997 / 2210\n",
      "998 / 2210\n",
      "999 / 2210\n",
      "1000 / 2210\n",
      "1001 / 2210\n",
      "1002 / 2210\n",
      "1003 / 2210\n",
      "1004 / 2210\n",
      "1005 / 2210\n",
      "1006 / 2210\n",
      "1007 / 2210\n",
      "1008 / 2210\n",
      "1009 / 2210\n",
      "1010 / 2210\n",
      "1011 / 2210\n",
      "1012 / 2210\n",
      "1013 / 2210\n",
      "1014 / 2210\n",
      "1015 / 2210\n",
      "1016 / 2210\n",
      "1017 / 2210\n",
      "1018 / 2210\n",
      "1019 / 2210\n",
      "1020 / 2210\n",
      "1021 / 2210\n",
      "1022 / 2210\n",
      "1023 / 2210\n",
      "1024 / 2210\n",
      "1025 / 2210\n",
      "1026 / 2210\n",
      "1027 / 2210\n",
      "1028 / 2210\n",
      "1029 / 2210\n",
      "1030 / 2210\n",
      "1031 / 2210\n",
      "1032 / 2210\n",
      "1033 / 2210\n",
      "1034 / 2210\n",
      "1035 / 2210\n",
      "1036 / 2210\n",
      "1037 / 2210\n",
      "1038 / 2210\n",
      "1039 / 2210\n",
      "1040 / 2210\n",
      "1041 / 2210\n",
      "1042 / 2210\n",
      "1043 / 2210\n",
      "1044 / 2210\n",
      "1045 / 2210\n",
      "1046 / 2210\n",
      "1047 / 2210\n",
      "1048 / 2210\n",
      "1049 / 2210\n",
      "1050 / 2210\n",
      "1051 / 2210\n",
      "1052 / 2210\n",
      "1053 / 2210\n",
      "1054 / 2210\n",
      "1055 / 2210\n",
      "1056 / 2210\n",
      "1057 / 2210\n",
      "1058 / 2210\n",
      "1059 / 2210\n",
      "1060 / 2210\n",
      "1061 / 2210\n",
      "1062 / 2210\n",
      "1063 / 2210\n",
      "1064 / 2210\n",
      "1065 / 2210\n",
      "1066 / 2210\n",
      "1067 / 2210\n",
      "1068 / 2210\n",
      "1069 / 2210\n",
      "1070 / 2210\n",
      "1071 / 2210\n",
      "1072 / 2210\n",
      "1073 / 2210\n",
      "1074 / 2210\n",
      "1075 / 2210\n",
      "1076 / 2210\n",
      "1077 / 2210\n",
      "1078 / 2210\n",
      "1079 / 2210\n",
      "1080 / 2210\n",
      "1081 / 2210\n",
      "1082 / 2210\n",
      "1083 / 2210\n",
      "1084 / 2210\n",
      "1085 / 2210\n",
      "1086 / 2210\n",
      "1087 / 2210\n",
      "1088 / 2210\n",
      "1089 / 2210\n",
      "1090 / 2210\n",
      "1091 / 2210\n",
      "1092 / 2210\n",
      "1093 / 2210\n",
      "1094 / 2210\n",
      "1095 / 2210\n",
      "1096 / 2210\n",
      "1097 / 2210\n",
      "1098 / 2210\n",
      "1099 / 2210\n",
      "1100 / 2210\n",
      "1101 / 2210\n",
      "1102 / 2210\n",
      "1103 / 2210\n",
      "1104 / 2210\n",
      "1105 / 2210\n",
      "1106 / 2210\n",
      "1107 / 2210\n",
      "1108 / 2210\n",
      "1109 / 2210\n",
      "1110 / 2210\n",
      "1111 / 2210\n",
      "1112 / 2210\n",
      "1113 / 2210\n",
      "1114 / 2210\n",
      "1115 / 2210\n",
      "1116 / 2210\n",
      "1117 / 2210\n",
      "1118 / 2210\n",
      "1119 / 2210\n",
      "1120 / 2210\n",
      "1121 / 2210\n",
      "1122 / 2210\n",
      "1123 / 2210\n",
      "1124 / 2210\n",
      "1125 / 2210\n",
      "1126 / 2210\n",
      "1127 / 2210\n",
      "1128 / 2210\n",
      "1129 / 2210\n",
      "1130 / 2210\n",
      "1131 / 2210\n",
      "1132 / 2210\n",
      "1133 / 2210\n",
      "1134 / 2210\n",
      "1135 / 2210\n",
      "1136 / 2210\n",
      "1137 / 2210\n",
      "1138 / 2210\n",
      "1139 / 2210\n",
      "1140 / 2210\n",
      "1141 / 2210\n",
      "1142 / 2210\n",
      "1143 / 2210\n",
      "1144 / 2210\n",
      "1145 / 2210\n",
      "1146 / 2210\n",
      "1147 / 2210\n",
      "1148 / 2210\n",
      "1149 / 2210\n",
      "1150 / 2210\n",
      "1151 / 2210\n",
      "1152 / 2210\n",
      "1153 / 2210\n",
      "1154 / 2210\n",
      "1155 / 2210\n",
      "1156 / 2210\n",
      "1157 / 2210\n",
      "1158 / 2210\n",
      "1159 / 2210\n",
      "1160 / 2210\n",
      "1161 / 2210\n",
      "1162 / 2210\n",
      "1163 / 2210\n",
      "1164 / 2210\n",
      "1165 / 2210\n",
      "1166 / 2210\n",
      "1167 / 2210\n",
      "1168 / 2210\n",
      "1169 / 2210\n",
      "1170 / 2210\n",
      "1171 / 2210\n",
      "1172 / 2210\n",
      "1173 / 2210\n",
      "1174 / 2210\n",
      "1175 / 2210\n",
      "1176 / 2210\n",
      "1177 / 2210\n",
      "1178 / 2210\n",
      "1179 / 2210\n",
      "1180 / 2210\n",
      "1181 / 2210\n",
      "1182 / 2210\n",
      "1183 / 2210\n",
      "1184 / 2210\n",
      "1185 / 2210\n",
      "1186 / 2210\n",
      "1187 / 2210\n",
      "1188 / 2210\n",
      "1189 / 2210\n",
      "1190 / 2210\n",
      "1191 / 2210\n",
      "1192 / 2210\n",
      "1193 / 2210\n",
      "1194 / 2210\n",
      "1195 / 2210\n",
      "1196 / 2210\n",
      "1197 / 2210\n",
      "1198 / 2210\n",
      "1199 / 2210\n",
      "1200 / 2210\n",
      "1201 / 2210\n",
      "1202 / 2210\n",
      "1203 / 2210\n",
      "1204 / 2210\n",
      "1205 / 2210\n",
      "1206 / 2210\n",
      "1207 / 2210\n",
      "1208 / 2210\n",
      "1209 / 2210\n",
      "1210 / 2210\n",
      "1211 / 2210\n",
      "1212 / 2210\n",
      "1213 / 2210\n",
      "1214 / 2210\n",
      "1215 / 2210\n",
      "1216 / 2210\n",
      "1217 / 2210\n",
      "1218 / 2210\n",
      "1219 / 2210\n",
      "1220 / 2210\n",
      "1221 / 2210\n",
      "1222 / 2210\n",
      "1223 / 2210\n",
      "1224 / 2210\n",
      "1225 / 2210\n",
      "1226 / 2210\n",
      "1227 / 2210\n",
      "1228 / 2210\n",
      "1229 / 2210\n",
      "1230 / 2210\n",
      "1231 / 2210\n",
      "1232 / 2210\n",
      "1233 / 2210\n",
      "1234 / 2210\n",
      "1235 / 2210\n",
      "1236 / 2210\n",
      "1237 / 2210\n",
      "1238 / 2210\n",
      "1239 / 2210\n",
      "1240 / 2210\n",
      "1241 / 2210\n",
      "1242 / 2210\n",
      "1243 / 2210\n",
      "1244 / 2210\n",
      "1245 / 2210\n",
      "1246 / 2210\n",
      "1247 / 2210\n",
      "1248 / 2210\n",
      "1249 / 2210\n",
      "1250 / 2210\n",
      "1251 / 2210\n",
      "1252 / 2210\n",
      "1253 / 2210\n",
      "1254 / 2210\n",
      "1255 / 2210\n",
      "1256 / 2210\n",
      "1257 / 2210\n",
      "1258 / 2210\n",
      "1259 / 2210\n",
      "1260 / 2210\n",
      "1261 / 2210\n",
      "1262 / 2210\n",
      "1263 / 2210\n",
      "1264 / 2210\n",
      "1265 / 2210\n",
      "1266 / 2210\n",
      "1267 / 2210\n",
      "1268 / 2210\n",
      "1269 / 2210\n",
      "1270 / 2210\n",
      "1271 / 2210\n",
      "1272 / 2210\n",
      "1273 / 2210\n",
      "1274 / 2210\n",
      "1275 / 2210\n",
      "1276 / 2210\n",
      "1277 / 2210\n",
      "1278 / 2210\n",
      "1279 / 2210\n",
      "1280 / 2210\n",
      "1281 / 2210\n",
      "1282 / 2210\n",
      "1283 / 2210\n",
      "1284 / 2210\n",
      "1285 / 2210\n",
      "1286 / 2210\n",
      "1287 / 2210\n",
      "1288 / 2210\n",
      "1289 / 2210\n",
      "1290 / 2210\n",
      "1291 / 2210\n",
      "1292 / 2210\n",
      "1293 / 2210\n",
      "1294 / 2210\n",
      "1295 / 2210\n",
      "1296 / 2210\n",
      "1297 / 2210\n",
      "1298 / 2210\n",
      "1299 / 2210\n",
      "1300 / 2210\n",
      "1301 / 2210\n",
      "1302 / 2210\n",
      "1303 / 2210\n",
      "1304 / 2210\n",
      "1305 / 2210\n",
      "1306 / 2210\n",
      "1307 / 2210\n",
      "1308 / 2210\n",
      "1309 / 2210\n",
      "1310 / 2210\n",
      "1311 / 2210\n",
      "1312 / 2210\n",
      "1313 / 2210\n",
      "1314 / 2210\n",
      "1315 / 2210\n",
      "1316 / 2210\n",
      "1317 / 2210\n",
      "1318 / 2210\n",
      "1319 / 2210\n",
      "1320 / 2210\n",
      "1321 / 2210\n",
      "1322 / 2210\n",
      "1323 / 2210\n",
      "1324 / 2210\n",
      "1325 / 2210\n",
      "1326 / 2210\n",
      "1327 / 2210\n",
      "1328 / 2210\n",
      "1329 / 2210\n",
      "1330 / 2210\n",
      "1331 / 2210\n",
      "1332 / 2210\n",
      "1333 / 2210\n",
      "1334 / 2210\n",
      "1335 / 2210\n",
      "1336 / 2210\n",
      "1337 / 2210\n",
      "1338 / 2210\n",
      "1339 / 2210\n",
      "1340 / 2210\n",
      "1341 / 2210\n",
      "1342 / 2210\n",
      "1343 / 2210\n",
      "1344 / 2210\n",
      "1345 / 2210\n",
      "1346 / 2210\n",
      "1347 / 2210\n",
      "1348 / 2210\n",
      "1349 / 2210\n",
      "1350 / 2210\n",
      "1351 / 2210\n",
      "1352 / 2210\n",
      "1353 / 2210\n",
      "1354 / 2210\n",
      "1355 / 2210\n",
      "1356 / 2210\n",
      "1357 / 2210\n",
      "1358 / 2210\n",
      "1359 / 2210\n",
      "1360 / 2210\n",
      "1361 / 2210\n",
      "1362 / 2210\n",
      "1363 / 2210\n",
      "1364 / 2210\n",
      "1365 / 2210\n",
      "1366 / 2210\n",
      "1367 / 2210\n",
      "1368 / 2210\n",
      "1369 / 2210\n",
      "1370 / 2210\n",
      "1371 / 2210\n",
      "1372 / 2210\n",
      "1373 / 2210\n",
      "1374 / 2210\n",
      "1375 / 2210\n",
      "1376 / 2210\n",
      "1377 / 2210\n",
      "1378 / 2210\n",
      "1379 / 2210\n",
      "1380 / 2210\n",
      "1381 / 2210\n",
      "1382 / 2210\n",
      "1383 / 2210\n",
      "1384 / 2210\n",
      "1385 / 2210\n",
      "1386 / 2210\n",
      "1387 / 2210\n",
      "1388 / 2210\n",
      "1389 / 2210\n",
      "1390 / 2210\n",
      "1391 / 2210\n",
      "1392 / 2210\n",
      "1393 / 2210\n",
      "1394 / 2210\n",
      "1395 / 2210\n",
      "1396 / 2210\n",
      "1397 / 2210\n",
      "1398 / 2210\n",
      "1399 / 2210\n",
      "1400 / 2210\n",
      "1401 / 2210\n",
      "1402 / 2210\n",
      "1403 / 2210\n",
      "1404 / 2210\n",
      "1405 / 2210\n",
      "1406 / 2210\n",
      "1407 / 2210\n",
      "1408 / 2210\n",
      "1409 / 2210\n",
      "1410 / 2210\n",
      "1411 / 2210\n",
      "1412 / 2210\n",
      "1413 / 2210\n",
      "1414 / 2210\n",
      "1415 / 2210\n",
      "1416 / 2210\n",
      "1417 / 2210\n",
      "1418 / 2210\n",
      "1419 / 2210\n",
      "1420 / 2210\n",
      "1421 / 2210\n",
      "1422 / 2210\n",
      "1423 / 2210\n",
      "1424 / 2210\n",
      "1425 / 2210\n",
      "1426 / 2210\n",
      "1427 / 2210\n",
      "1428 / 2210\n",
      "1429 / 2210\n",
      "1430 / 2210\n",
      "1431 / 2210\n",
      "1432 / 2210\n",
      "1433 / 2210\n",
      "1434 / 2210\n",
      "1435 / 2210\n",
      "1436 / 2210\n",
      "1437 / 2210\n",
      "1438 / 2210\n",
      "1439 / 2210\n",
      "1440 / 2210\n",
      "1441 / 2210\n",
      "1442 / 2210\n",
      "1443 / 2210\n",
      "1444 / 2210\n",
      "1445 / 2210\n",
      "1446 / 2210\n",
      "1447 / 2210\n",
      "1448 / 2210\n",
      "1449 / 2210\n",
      "1450 / 2210\n",
      "1451 / 2210\n",
      "1452 / 2210\n",
      "1453 / 2210\n",
      "1454 / 2210\n",
      "1455 / 2210\n",
      "1456 / 2210\n",
      "1457 / 2210\n",
      "1458 / 2210\n",
      "1459 / 2210\n",
      "1460 / 2210\n",
      "1461 / 2210\n",
      "1462 / 2210\n",
      "1463 / 2210\n",
      "1464 / 2210\n",
      "1465 / 2210\n",
      "1466 / 2210\n",
      "1467 / 2210\n",
      "1468 / 2210\n",
      "1469 / 2210\n",
      "1470 / 2210\n",
      "1471 / 2210\n",
      "1472 / 2210\n",
      "1473 / 2210\n",
      "1474 / 2210\n",
      "1475 / 2210\n",
      "1476 / 2210\n",
      "1477 / 2210\n",
      "1478 / 2210\n",
      "1479 / 2210\n",
      "1480 / 2210\n",
      "1481 / 2210\n",
      "1482 / 2210\n",
      "1483 / 2210\n",
      "1484 / 2210\n",
      "1485 / 2210\n",
      "1486 / 2210\n",
      "1487 / 2210\n",
      "1488 / 2210\n",
      "1489 / 2210\n",
      "1490 / 2210\n",
      "1491 / 2210\n",
      "1492 / 2210\n",
      "1493 / 2210\n",
      "1494 / 2210\n",
      "1495 / 2210\n",
      "1496 / 2210\n",
      "1497 / 2210\n",
      "1498 / 2210\n",
      "1499 / 2210\n",
      "1500 / 2210\n",
      "1501 / 2210\n",
      "1502 / 2210\n",
      "1503 / 2210\n",
      "1504 / 2210\n",
      "1505 / 2210\n",
      "1506 / 2210\n",
      "1507 / 2210\n",
      "1508 / 2210\n",
      "1509 / 2210\n",
      "1510 / 2210\n",
      "1511 / 2210\n",
      "1512 / 2210\n",
      "1513 / 2210\n",
      "1514 / 2210\n",
      "1515 / 2210\n",
      "1516 / 2210\n",
      "1517 / 2210\n",
      "1518 / 2210\n",
      "1519 / 2210\n",
      "1520 / 2210\n",
      "1521 / 2210\n",
      "1522 / 2210\n",
      "1523 / 2210\n",
      "1524 / 2210\n",
      "1525 / 2210\n",
      "1526 / 2210\n",
      "1527 / 2210\n",
      "1528 / 2210\n",
      "1529 / 2210\n",
      "1530 / 2210\n",
      "1531 / 2210\n",
      "1532 / 2210\n",
      "1533 / 2210\n",
      "1534 / 2210\n",
      "1535 / 2210\n",
      "1536 / 2210\n",
      "1537 / 2210\n",
      "1538 / 2210\n",
      "1539 / 2210\n",
      "1540 / 2210\n",
      "1541 / 2210\n",
      "1542 / 2210\n",
      "1543 / 2210\n",
      "1544 / 2210\n",
      "1545 / 2210\n",
      "1546 / 2210\n",
      "1547 / 2210\n",
      "1548 / 2210\n",
      "1549 / 2210\n",
      "1550 / 2210\n",
      "1551 / 2210\n",
      "1552 / 2210\n",
      "1553 / 2210\n",
      "1554 / 2210\n",
      "1555 / 2210\n",
      "1556 / 2210\n",
      "1557 / 2210\n",
      "1558 / 2210\n",
      "1559 / 2210\n",
      "1560 / 2210\n",
      "1561 / 2210\n",
      "1562 / 2210\n",
      "1563 / 2210\n",
      "1564 / 2210\n",
      "1565 / 2210\n",
      "1566 / 2210\n",
      "1567 / 2210\n",
      "1568 / 2210\n",
      "1569 / 2210\n",
      "1570 / 2210\n",
      "1571 / 2210\n",
      "1572 / 2210\n",
      "1573 / 2210\n",
      "1574 / 2210\n",
      "1575 / 2210\n",
      "1576 / 2210\n",
      "1577 / 2210\n",
      "1578 / 2210\n",
      "1579 / 2210\n",
      "1580 / 2210\n",
      "1581 / 2210\n",
      "1582 / 2210\n",
      "1583 / 2210\n",
      "1584 / 2210\n",
      "1585 / 2210\n",
      "1586 / 2210\n",
      "1587 / 2210\n",
      "1588 / 2210\n",
      "1589 / 2210\n",
      "1590 / 2210\n",
      "1591 / 2210\n",
      "1592 / 2210\n",
      "1593 / 2210\n",
      "1594 / 2210\n",
      "1595 / 2210\n",
      "1596 / 2210\n",
      "1597 / 2210\n",
      "1598 / 2210\n",
      "1599 / 2210\n",
      "1600 / 2210\n",
      "1601 / 2210\n",
      "1602 / 2210\n",
      "1603 / 2210\n",
      "1604 / 2210\n",
      "1605 / 2210\n",
      "1606 / 2210\n",
      "1607 / 2210\n",
      "1608 / 2210\n",
      "1609 / 2210\n",
      "1610 / 2210\n",
      "1611 / 2210\n",
      "1612 / 2210\n",
      "1613 / 2210\n",
      "1614 / 2210\n",
      "1615 / 2210\n",
      "1616 / 2210\n",
      "1617 / 2210\n",
      "1618 / 2210\n",
      "1619 / 2210\n",
      "1620 / 2210\n",
      "1621 / 2210\n",
      "1622 / 2210\n",
      "1623 / 2210\n",
      "1624 / 2210\n",
      "1625 / 2210\n",
      "1626 / 2210\n",
      "1627 / 2210\n",
      "1628 / 2210\n",
      "1629 / 2210\n",
      "1630 / 2210\n",
      "1631 / 2210\n",
      "1632 / 2210\n",
      "1633 / 2210\n",
      "1634 / 2210\n",
      "1635 / 2210\n",
      "1636 / 2210\n",
      "1637 / 2210\n",
      "1638 / 2210\n",
      "1639 / 2210\n",
      "1640 / 2210\n",
      "1641 / 2210\n",
      "1642 / 2210\n",
      "1643 / 2210\n",
      "1644 / 2210\n",
      "1645 / 2210\n",
      "1646 / 2210\n",
      "1647 / 2210\n",
      "1648 / 2210\n",
      "1649 / 2210\n",
      "1650 / 2210\n",
      "1651 / 2210\n",
      "1652 / 2210\n",
      "1653 / 2210\n",
      "1654 / 2210\n",
      "1655 / 2210\n",
      "1656 / 2210\n",
      "1657 / 2210\n",
      "1658 / 2210\n",
      "1659 / 2210\n",
      "1660 / 2210\n",
      "1661 / 2210\n",
      "1662 / 2210\n",
      "1663 / 2210\n",
      "1664 / 2210\n",
      "1665 / 2210\n",
      "1666 / 2210\n",
      "1667 / 2210\n",
      "1668 / 2210\n",
      "1669 / 2210\n",
      "1670 / 2210\n",
      "1671 / 2210\n",
      "1672 / 2210\n",
      "1673 / 2210\n",
      "1674 / 2210\n",
      "1675 / 2210\n",
      "1676 / 2210\n",
      "1677 / 2210\n",
      "1678 / 2210\n",
      "1679 / 2210\n",
      "1680 / 2210\n",
      "1681 / 2210\n",
      "1682 / 2210\n",
      "1683 / 2210\n",
      "1684 / 2210\n",
      "1685 / 2210\n",
      "1686 / 2210\n",
      "1687 / 2210\n",
      "1688 / 2210\n",
      "1689 / 2210\n",
      "1690 / 2210\n",
      "1691 / 2210\n",
      "1692 / 2210\n",
      "1693 / 2210\n",
      "1694 / 2210\n",
      "1695 / 2210\n",
      "1696 / 2210\n",
      "1697 / 2210\n",
      "1698 / 2210\n",
      "1699 / 2210\n",
      "1700 / 2210\n",
      "1701 / 2210\n",
      "1702 / 2210\n",
      "1703 / 2210\n",
      "1704 / 2210\n",
      "1705 / 2210\n",
      "1706 / 2210\n",
      "1707 / 2210\n",
      "1708 / 2210\n",
      "1709 / 2210\n",
      "1710 / 2210\n",
      "1711 / 2210\n",
      "1712 / 2210\n",
      "1713 / 2210\n",
      "1714 / 2210\n",
      "1715 / 2210\n",
      "1716 / 2210\n",
      "1717 / 2210\n",
      "1718 / 2210\n",
      "1719 / 2210\n",
      "1720 / 2210\n",
      "1721 / 2210\n",
      "1722 / 2210\n",
      "1723 / 2210\n",
      "1724 / 2210\n",
      "1725 / 2210\n",
      "1726 / 2210\n",
      "1727 / 2210\n",
      "1728 / 2210\n",
      "1729 / 2210\n",
      "1730 / 2210\n",
      "1731 / 2210\n",
      "1732 / 2210\n",
      "1733 / 2210\n",
      "1734 / 2210\n",
      "1735 / 2210\n",
      "1736 / 2210\n",
      "1737 / 2210\n",
      "1738 / 2210\n",
      "1739 / 2210\n",
      "1740 / 2210\n",
      "1741 / 2210\n",
      "1742 / 2210\n",
      "1743 / 2210\n",
      "1744 / 2210\n",
      "1745 / 2210\n",
      "1746 / 2210\n",
      "1747 / 2210\n",
      "1748 / 2210\n",
      "1749 / 2210\n",
      "1750 / 2210\n",
      "1751 / 2210\n",
      "1752 / 2210\n",
      "1753 / 2210\n",
      "1754 / 2210\n",
      "1755 / 2210\n",
      "1756 / 2210\n",
      "1757 / 2210\n",
      "1758 / 2210\n",
      "1759 / 2210\n",
      "1760 / 2210\n",
      "1761 / 2210\n",
      "1762 / 2210\n",
      "1763 / 2210\n",
      "1764 / 2210\n",
      "1765 / 2210\n",
      "1766 / 2210\n",
      "1767 / 2210\n",
      "1768 / 2210\n",
      "1769 / 2210\n",
      "1770 / 2210\n",
      "1771 / 2210\n",
      "1772 / 2210\n",
      "1773 / 2210\n",
      "1774 / 2210\n",
      "1775 / 2210\n",
      "1776 / 2210\n",
      "1777 / 2210\n",
      "1778 / 2210\n",
      "1779 / 2210\n",
      "1780 / 2210\n",
      "1781 / 2210\n",
      "1782 / 2210\n",
      "1783 / 2210\n",
      "1784 / 2210\n",
      "1785 / 2210\n",
      "1786 / 2210\n",
      "1787 / 2210\n",
      "1788 / 2210\n",
      "1789 / 2210\n",
      "1790 / 2210\n",
      "1791 / 2210\n",
      "1792 / 2210\n",
      "1793 / 2210\n",
      "1794 / 2210\n",
      "1795 / 2210\n",
      "1796 / 2210\n",
      "1797 / 2210\n",
      "1798 / 2210\n",
      "1799 / 2210\n",
      "1800 / 2210\n",
      "1801 / 2210\n",
      "1802 / 2210\n",
      "1803 / 2210\n",
      "1804 / 2210\n",
      "1805 / 2210\n",
      "1806 / 2210\n",
      "1807 / 2210\n",
      "1808 / 2210\n",
      "1809 / 2210\n",
      "1810 / 2210\n",
      "1811 / 2210\n",
      "1812 / 2210\n",
      "1813 / 2210\n",
      "1814 / 2210\n",
      "1815 / 2210\n",
      "1816 / 2210\n",
      "1817 / 2210\n",
      "1818 / 2210\n",
      "1819 / 2210\n",
      "1820 / 2210\n",
      "1821 / 2210\n",
      "1822 / 2210\n",
      "1823 / 2210\n",
      "1824 / 2210\n",
      "1825 / 2210\n",
      "1826 / 2210\n",
      "1827 / 2210\n",
      "1828 / 2210\n",
      "1829 / 2210\n",
      "1830 / 2210\n",
      "1831 / 2210\n",
      "1832 / 2210\n",
      "1833 / 2210\n",
      "1834 / 2210\n",
      "1835 / 2210\n",
      "1836 / 2210\n",
      "1837 / 2210\n",
      "1838 / 2210\n",
      "1839 / 2210\n",
      "1840 / 2210\n",
      "1841 / 2210\n",
      "1842 / 2210\n",
      "1843 / 2210\n",
      "1844 / 2210\n",
      "1845 / 2210\n",
      "1846 / 2210\n",
      "1847 / 2210\n",
      "1848 / 2210\n",
      "1849 / 2210\n",
      "1850 / 2210\n",
      "1851 / 2210\n",
      "1852 / 2210\n",
      "1853 / 2210\n",
      "1854 / 2210\n",
      "1855 / 2210\n",
      "1856 / 2210\n",
      "1857 / 2210\n",
      "1858 / 2210\n",
      "1859 / 2210\n",
      "1860 / 2210\n",
      "1861 / 2210\n",
      "1862 / 2210\n",
      "1863 / 2210\n",
      "1864 / 2210\n",
      "1865 / 2210\n",
      "1866 / 2210\n",
      "1867 / 2210\n",
      "1868 / 2210\n",
      "1869 / 2210\n",
      "1870 / 2210\n",
      "1871 / 2210\n",
      "1872 / 2210\n",
      "1873 / 2210\n",
      "1874 / 2210\n",
      "1875 / 2210\n",
      "1876 / 2210\n",
      "1877 / 2210\n",
      "1878 / 2210\n",
      "1879 / 2210\n",
      "1880 / 2210\n",
      "1881 / 2210\n",
      "1882 / 2210\n",
      "1883 / 2210\n",
      "1884 / 2210\n",
      "1885 / 2210\n",
      "1886 / 2210\n",
      "1887 / 2210\n",
      "1888 / 2210\n",
      "1889 / 2210\n",
      "1890 / 2210\n",
      "1891 / 2210\n",
      "1892 / 2210\n",
      "1893 / 2210\n",
      "1894 / 2210\n",
      "1895 / 2210\n",
      "1896 / 2210\n",
      "1897 / 2210\n",
      "1898 / 2210\n",
      "1899 / 2210\n",
      "1900 / 2210\n",
      "1901 / 2210\n",
      "1902 / 2210\n",
      "1903 / 2210\n",
      "1904 / 2210\n",
      "1905 / 2210\n",
      "1906 / 2210\n",
      "1907 / 2210\n",
      "1908 / 2210\n",
      "1909 / 2210\n",
      "1910 / 2210\n",
      "1911 / 2210\n",
      "1912 / 2210\n",
      "1913 / 2210\n",
      "1914 / 2210\n",
      "1915 / 2210\n",
      "1916 / 2210\n",
      "1917 / 2210\n",
      "1918 / 2210\n",
      "1919 / 2210\n",
      "1920 / 2210\n",
      "1921 / 2210\n",
      "1922 / 2210\n",
      "1923 / 2210\n",
      "1924 / 2210\n",
      "1925 / 2210\n",
      "1926 / 2210\n",
      "1927 / 2210\n",
      "1928 / 2210\n",
      "1929 / 2210\n",
      "1930 / 2210\n",
      "1931 / 2210\n",
      "1932 / 2210\n",
      "1933 / 2210\n",
      "1934 / 2210\n",
      "1935 / 2210\n",
      "1936 / 2210\n",
      "1937 / 2210\n",
      "1938 / 2210\n",
      "1939 / 2210\n",
      "1940 / 2210\n",
      "1941 / 2210\n",
      "1942 / 2210\n",
      "1943 / 2210\n",
      "1944 / 2210\n",
      "1945 / 2210\n",
      "1946 / 2210\n",
      "1947 / 2210\n",
      "1948 / 2210\n",
      "1949 / 2210\n",
      "1950 / 2210\n",
      "1951 / 2210\n",
      "1952 / 2210\n",
      "1953 / 2210\n",
      "1954 / 2210\n",
      "1955 / 2210\n",
      "1956 / 2210\n",
      "1957 / 2210\n",
      "1958 / 2210\n",
      "1959 / 2210\n",
      "1960 / 2210\n",
      "1961 / 2210\n",
      "1962 / 2210\n",
      "1963 / 2210\n",
      "1964 / 2210\n",
      "1965 / 2210\n",
      "1966 / 2210\n",
      "1967 / 2210\n",
      "1968 / 2210\n",
      "1969 / 2210\n",
      "1970 / 2210\n",
      "1971 / 2210\n",
      "1972 / 2210\n",
      "1973 / 2210\n",
      "1974 / 2210\n",
      "1975 / 2210\n",
      "1976 / 2210\n",
      "1977 / 2210\n",
      "1978 / 2210\n",
      "1979 / 2210\n",
      "1980 / 2210\n",
      "1981 / 2210\n",
      "1982 / 2210\n",
      "1983 / 2210\n",
      "1984 / 2210\n",
      "1985 / 2210\n",
      "1986 / 2210\n",
      "1987 / 2210\n",
      "1988 / 2210\n",
      "1989 / 2210\n",
      "1990 / 2210\n",
      "1991 / 2210\n",
      "1992 / 2210\n",
      "1993 / 2210\n",
      "1994 / 2210\n",
      "1995 / 2210\n",
      "1996 / 2210\n",
      "1997 / 2210\n",
      "1998 / 2210\n",
      "1999 / 2210\n",
      "2000 / 2210\n",
      "2001 / 2210\n",
      "2002 / 2210\n",
      "2003 / 2210\n",
      "2004 / 2210\n",
      "2005 / 2210\n",
      "2006 / 2210\n",
      "2007 / 2210\n",
      "2008 / 2210\n",
      "2009 / 2210\n",
      "2010 / 2210\n",
      "2011 / 2210\n",
      "2012 / 2210\n",
      "2013 / 2210\n",
      "2014 / 2210\n",
      "2015 / 2210\n",
      "2016 / 2210\n",
      "2017 / 2210\n",
      "2018 / 2210\n",
      "2019 / 2210\n",
      "2020 / 2210\n",
      "2021 / 2210\n",
      "2022 / 2210\n",
      "2023 / 2210\n",
      "2024 / 2210\n",
      "2025 / 2210\n",
      "2026 / 2210\n",
      "2027 / 2210\n",
      "2028 / 2210\n",
      "2029 / 2210\n",
      "2030 / 2210\n",
      "2031 / 2210\n",
      "2032 / 2210\n",
      "2033 / 2210\n",
      "2034 / 2210\n",
      "2035 / 2210\n",
      "2036 / 2210\n",
      "2037 / 2210\n",
      "2038 / 2210\n",
      "2039 / 2210\n",
      "2040 / 2210\n",
      "2041 / 2210\n",
      "2042 / 2210\n",
      "2043 / 2210\n",
      "2044 / 2210\n",
      "2045 / 2210\n",
      "2046 / 2210\n",
      "2047 / 2210\n",
      "2048 / 2210\n",
      "2049 / 2210\n",
      "2050 / 2210\n",
      "2051 / 2210\n",
      "2052 / 2210\n",
      "2053 / 2210\n",
      "2054 / 2210\n",
      "2055 / 2210\n",
      "2056 / 2210\n",
      "2057 / 2210\n",
      "2058 / 2210\n",
      "2059 / 2210\n",
      "2060 / 2210\n",
      "2061 / 2210\n",
      "2062 / 2210\n",
      "2063 / 2210\n",
      "2064 / 2210\n",
      "2065 / 2210\n",
      "2066 / 2210\n",
      "2067 / 2210\n",
      "2068 / 2210\n",
      "2069 / 2210\n",
      "2070 / 2210\n",
      "2071 / 2210\n",
      "2072 / 2210\n",
      "2073 / 2210\n",
      "2074 / 2210\n",
      "2075 / 2210\n",
      "2076 / 2210\n",
      "2077 / 2210\n",
      "2078 / 2210\n",
      "2079 / 2210\n",
      "2080 / 2210\n",
      "2081 / 2210\n",
      "2082 / 2210\n",
      "2083 / 2210\n",
      "2084 / 2210\n",
      "2085 / 2210\n",
      "2086 / 2210\n",
      "2087 / 2210\n",
      "2088 / 2210\n",
      "2089 / 2210\n",
      "2090 / 2210\n",
      "2091 / 2210\n",
      "2092 / 2210\n",
      "2093 / 2210\n",
      "2094 / 2210\n",
      "2095 / 2210\n",
      "2096 / 2210\n",
      "2097 / 2210\n",
      "2098 / 2210\n",
      "2099 / 2210\n",
      "2100 / 2210\n",
      "2101 / 2210\n",
      "2102 / 2210\n",
      "2103 / 2210\n",
      "2104 / 2210\n",
      "2105 / 2210\n",
      "2106 / 2210\n",
      "2107 / 2210\n",
      "2108 / 2210\n",
      "2109 / 2210\n",
      "2110 / 2210\n",
      "2111 / 2210\n",
      "2112 / 2210\n",
      "2113 / 2210\n",
      "2114 / 2210\n",
      "2115 / 2210\n",
      "2116 / 2210\n",
      "2117 / 2210\n",
      "2118 / 2210\n",
      "2119 / 2210\n",
      "2120 / 2210\n",
      "2121 / 2210\n",
      "2122 / 2210\n",
      "2123 / 2210\n",
      "2124 / 2210\n",
      "2125 / 2210\n",
      "2126 / 2210\n",
      "2127 / 2210\n",
      "2128 / 2210\n",
      "2129 / 2210\n",
      "2130 / 2210\n",
      "2131 / 2210\n",
      "2132 / 2210\n",
      "2133 / 2210\n",
      "2134 / 2210\n",
      "2135 / 2210\n",
      "2136 / 2210\n",
      "2137 / 2210\n",
      "2138 / 2210\n",
      "2139 / 2210\n",
      "2140 / 2210\n",
      "2141 / 2210\n",
      "2142 / 2210\n",
      "2143 / 2210\n",
      "2144 / 2210\n",
      "2145 / 2210\n",
      "2146 / 2210\n",
      "2147 / 2210\n",
      "2148 / 2210\n",
      "2149 / 2210\n",
      "2150 / 2210\n",
      "2151 / 2210\n",
      "2152 / 2210\n",
      "2153 / 2210\n",
      "2154 / 2210\n",
      "2155 / 2210\n",
      "2156 / 2210\n",
      "2157 / 2210\n",
      "2158 / 2210\n",
      "2159 / 2210\n",
      "2160 / 2210\n",
      "2161 / 2210\n",
      "2162 / 2210\n",
      "2163 / 2210\n",
      "2164 / 2210\n",
      "2165 / 2210\n",
      "2166 / 2210\n",
      "2167 / 2210\n",
      "2168 / 2210\n",
      "2169 / 2210\n",
      "2170 / 2210\n",
      "2171 / 2210\n",
      "2172 / 2210\n",
      "2173 / 2210\n",
      "2174 / 2210\n",
      "2175 / 2210\n",
      "2176 / 2210\n",
      "2177 / 2210\n",
      "2178 / 2210\n",
      "2179 / 2210\n",
      "2180 / 2210\n",
      "2181 / 2210\n",
      "2182 / 2210\n",
      "2183 / 2210\n",
      "2184 / 2210\n",
      "2185 / 2210\n",
      "2186 / 2210\n",
      "2187 / 2210\n",
      "2188 / 2210\n",
      "2189 / 2210\n",
      "2190 / 2210\n",
      "2191 / 2210\n",
      "2192 / 2210\n",
      "2193 / 2210\n",
      "2194 / 2210\n",
      "2195 / 2210\n",
      "2196 / 2210\n",
      "2197 / 2210\n",
      "2198 / 2210\n",
      "2199 / 2210\n",
      "2200 / 2210\n",
      "2201 / 2210\n",
      "2202 / 2210\n",
      "2203 / 2210\n",
      "2204 / 2210\n",
      "2205 / 2210\n",
      "2206 / 2210\n",
      "2207 / 2210\n",
      "2208 / 2210\n",
      "2209 / 2210\n"
     ]
    }
   ],
   "source": [
    "k_size_val = 3\n",
    "\n",
    "protein_kmers_list = []\n",
    "for protein_kmers in range(len(sequences)):\n",
    "    print(protein_kmers, \"/\",len(sequences))\n",
    "    k_mers_vals = build_kmers(sequences[protein_kmers],k_size_val)\n",
    "\n",
    "    # str(k_mers_vals[0])\n",
    "    k_mers_list = []\n",
    "    for mers_ind in range(len(k_mers_vals)):\n",
    "        k_mers_list.append(str(k_mers_vals[mers_ind]))\n",
    "        \n",
    "    protein_kmers_list.append(k_mers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_kmers_final = []\n",
    "for i in range(len(protein_kmers_list)):\n",
    "    tmp = protein_kmers_list[i]\n",
    "    tmp_seq = []\n",
    "    for j in range(len(protein_kmers_list[i])):\n",
    "        aa = tmp[j]\n",
    "        aa_lst = str(list(aa))\n",
    "        aa_lst_1 = aa_lst.replace(\",\",\"\")\n",
    "        aa_lst_2 = aa_lst_1.replace(\"[\",\"\")\n",
    "        aa_lst_3 = aa_lst_2.replace(\"\\\"\",\"\")\n",
    "        aa_lst_4 = aa_lst_3.replace(\"]\",\"\")\n",
    "        aa_lst_5 = aa_lst_4.replace(\"'\",\"\")\n",
    "        aa_lst_6 = aa_lst_5.replace(\" \",\"\")\n",
    "        tmp_seq.append(aa_lst_6)\n",
    "    seq_kmers_final.append(tmp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_seq_kmers_final_list = [''.join(c) for c in product('ACDEFGHIKLMNPQRSTVWXY*', repeat=3)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Frequency Vector from k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_vector = []\n",
    "#cnt_check2 = 0\n",
    "for ii in range(len(seq_kmers_final)):\n",
    "    seq_tmp = seq_kmers_final[ii]\n",
    "    listofzeros = [0] * len(unique_seq_kmers_final_list)\n",
    "    for j in range(len(seq_tmp)):\n",
    "        ind_tmp = unique_seq_kmers_final_list.index(seq_tmp[j])\n",
    "        listofzeros[ind_tmp] = listofzeros[ind_tmp] + 1\n",
    "    frequency_vector.append(listofzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1269, 1271)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(frequency_vector[0]),len(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hst = list(np.unique(host_names))\n",
    "len(unique_hst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute data preprocessing Done\n"
     ]
    }
   ],
   "source": [
    "int_hosts = []\n",
    "for ind_unique in range(len(host_names)):\n",
    "    variant_tmp = host_names[ind_unique]\n",
    "    ind_tmp = unique_hst.index(variant_tmp)\n",
    "    int_hosts.append(ind_tmp)\n",
    "    \n",
    "print(\"Attribute data preprocessing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(int_hosts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return mean(check)\n",
    "\n",
    "def svm_fun_kernel(X_train,y_train,X_test,y_test,kernel_mat):\n",
    "\n",
    "#     clf = svm.SVC()\n",
    "    clf = svm.SVC(kernel=kernel_mat)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    clf.fit(kernel_mat, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Kernel Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "# In[5]\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Gaussian NB Accuracy:\",NB_acc)\n",
    "\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Precision:\",NB_prec)\n",
    "    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Recall:\",NB_recall)\n",
    "    \n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB F1 weighted:\",NB_f1_weighted)\n",
    "    \n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Gaussian NB F1 macro:\",NB_f1_macro)\n",
    "    \n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Gaussian NB F1 micro:\",NB_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,NB_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Finally for the MLP- Multilayer Perceptron\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"MLP Accuracy:\",MLP_acc)\n",
    "    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Precision:\",MLP_prec)\n",
    "    \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Recall:\",MLP_recall)\n",
    "    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP F1:\",MLP_f1_weighted)\n",
    "    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"MLP F1:\",MLP_f1_macro)\n",
    "    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"MLP F1:\",MLP_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,MLP_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Knn Accuracy:\",knn_acc)\n",
    "    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Precision:\",knn_prec)\n",
    "    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Recall:\",knn_recall)\n",
    "    \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn F1 weighted:\",knn_f1_weighted)\n",
    "    \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Knn F1 macro:\",knn_f1_macro)\n",
    "    \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Knn F1 micro:\",knn_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,knn_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Random Forest Accuracy:\",fr_acc)\n",
    "    \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Precision:\",fr_prec)\n",
    "    \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Recall:\",fr_recall)\n",
    "    \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest F1 weighted:\",fr_f1_weighted)\n",
    "    \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Random Forest F1 macro:\",fr_f1_macro)\n",
    "    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Random Forest F1 micro:\",fr_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,fr_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "    ##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,LR_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,dt_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(frequency_vector)\n",
    "y = np.array(int_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-13-cec0359551a8>:130: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   1   0   0   4   0   2   0   0   0   1   0   0]\n",
      " [  0  12 190   0   5   0   1  18   0  11   5   0   0  48   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   3   7   0   5   0   0   6   0   2   1   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   1   0   0   0   5   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   6   0   0   0   0 135   2 154   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   0   0   1   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   5   0   0   0   0   0   0   0   0   0   0   5   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "NB Class Wise Accuracy :  [1.         0.2        0.65517241 0.         0.2        0.\n",
      " 0.83333333 1.         0.         0.51851852 0.         0.\n",
      " 0.         0.5        0.8               nan]\n",
      "NB Time :  1.4817367999999647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix MLP : \n",
      " [[  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2   7   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   1 277   0   1   0   1   0   0   3   0   0   0   3   4]\n",
      " [  0   0   1   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0   0  18   0   4   0   0   0   0   0   0   0   0   0   3]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   5   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   1   0   3   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0  27   1   0   0   0   4   0 264   1   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   1   3   0   0   0   0   0   0   0   0   0   0   6   0]\n",
      " [  0   1   1   0   0   0   0   0   0   0   0   0   0   0   3]]\n",
      "MLP Class Wise Accuracy :  [0.         0.2        0.95517241 0.         0.16       0.\n",
      " 0.83333333 0.25       0.         0.88888889 0.         0.\n",
      " 0.         0.6        0.6       ]\n",
      "MLP Time :  15.467537800000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-13-cec0359551a8>:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN : \n",
      " [[  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   9   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2 276   0   0   0   2   0   0   9   0   0   0   1   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   3   0  19   0   1   0   0   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   3   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0   0  41   0   0   0   0   1   0 255   0   0   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   9   0   0   0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   1   0   0   0   1   0   0   1   0   0   0   0   2]]\n",
      "KNN Class Wise Accuracy :  [1.         0.                nan 0.95172414 0.         0.04\n",
      " 0.         0.83333333 0.25       0.         0.85858586 0.\n",
      " 0.         0.         0.1        0.4       ]\n",
      "KNN Time :  10.01741179999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix RF : \n",
      " [[  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 285   0   0   0   1   0   0   1   0   0   0   3   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  21   0   3   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   6   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0  29   0   0   0   0   3   0 265   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   5   0   0   0   0   0   0   0   0   0   0   5   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   3]]\n",
      "RF Class Wise Accuracy :  [0.         0.1        0.98275862 0.         0.12       0.\n",
      " 1.         0.5        0.         0.89225589 0.         0.\n",
      " 0.         0.5        0.6       ]\n",
      "RF Time :  3.5303805000000352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LR : \n",
      " [[  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2   7   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0 282   0   0   0   0   0   0   6   0   0   0   2   0]\n",
      " [  0   0   1   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  19   0   4   0   0   0   0   2   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   3   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0  28   0   0   0   0   1   0 268   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   7   0]\n",
      " [  0   0   1   0   0   0   0   0   0   1   0   0   0   0   3]]\n",
      "LR Class Wise Accuracy :  [0.         0.2        0.97241379 0.5        0.16       0.\n",
      " 0.83333333 0.25       0.         0.9023569  0.         0.\n",
      " 0.         0.7        0.6       ]\n",
      "LR Time :  7.889174700000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix DT : \n",
      " [[  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2 277   0   3   0   0   0   0   5   0   0   0   3   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   2  20   0   1   0   0   0   0   1   0   0   0   1   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   5   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0  29   0   0   0   0   3   0 265   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   6   0   0   0   0   0   0   1   0   0   0   3   0]\n",
      " [  0   0   1   0   0   0   1   0   0   0   0   0   0   0   3]]\n",
      "DT Class Wise Accuracy :  [1.         0.1        0.95517241 0.         0.04       0.\n",
      " 0.83333333 0.5        0.         0.89225589 0.         0.\n",
      " 0.         0.3        0.6       ]\n",
      "DT Time :  0.6143285999999648\n",
      "Confusion Matrix SVM : \n",
      " [[  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   2   7   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   1 282   0   0   0   0   0   0   4   0   0   0   3   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  21   0   3   0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   6   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   3   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5   0   0   0   0   0]\n",
      " [  0   0  29   0   0   0   0   1   0 267   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   1   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   8   0]\n",
      " [  0   0   1   0   0   0   0   0   0   1   0   0   0   0   3]]\n",
      "SVM Class Wise Accuracy :  [1.         0.2        0.97241379 1.         0.12       0.\n",
      " 1.         0.25       0.         0.8989899  0.         0.\n",
      " 0.         0.8        0.6       ]\n",
      "SVM Time :  22.29683540000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "svm_table.append(svm_return)\n",
    "     \n",
    "svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.862292</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.846391</td>\n",
       "      <td>0.473910</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.720515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.559578</td>\n",
       "      <td>0.833225</td>\n",
       "      <td>0.559578</td>\n",
       "      <td>0.657710</td>\n",
       "      <td>0.297251</td>\n",
       "      <td>0.559578</td>\n",
       "      <td>0.679774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.838071</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.830666</td>\n",
       "      <td>0.291313</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.641419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.809110</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.788550</td>\n",
       "      <td>0.287215</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.636244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.859729</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.859729</td>\n",
       "      <td>0.833946</td>\n",
       "      <td>0.324755</td>\n",
       "      <td>0.859729</td>\n",
       "      <td>0.648442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.864253</td>\n",
       "      <td>0.857714</td>\n",
       "      <td>0.864253</td>\n",
       "      <td>0.841105</td>\n",
       "      <td>0.384582</td>\n",
       "      <td>0.864253</td>\n",
       "      <td>0.662682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.807860</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.819145</td>\n",
       "      <td>0.356442</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.665354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "SVM  0.868778   0.862292  0.868778       0.846391    0.473910    0.868778   \n",
       "NB   0.559578   0.833225  0.559578       0.657710    0.297251    0.559578   \n",
       "MLP  0.847662   0.838071  0.847662       0.830666    0.291313    0.847662   \n",
       "KNN  0.819005   0.809110  0.819005       0.788550    0.287215    0.819005   \n",
       "RF   0.859729   0.856923  0.859729       0.833946    0.324755    0.859729   \n",
       "LR   0.864253   0.857714  0.864253       0.841105    0.384582    0.864253   \n",
       "DT   0.843137   0.807860  0.843137       0.819145    0.356442    0.843137   \n",
       "\n",
       "      ROC AUC  \n",
       "SVM  0.720515  \n",
       "NB   0.679774  \n",
       "MLP  0.641419  \n",
       "KNN  0.636244  \n",
       "RF   0.648442  \n",
       "LR   0.662682  \n",
       "DT   0.665354  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
