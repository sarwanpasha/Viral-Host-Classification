{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "# import seaborn as sns\n",
    "import os.path as path\n",
    "import os\n",
    "# import matplotlib\n",
    "# import matplotlib.font_manager\n",
    "# import matplotlib.pyplot as plt # graphs plotting\n",
    "# import Bio\n",
    "from Bio import SeqIO # some BioPython that will come in handy\n",
    "#matplotlib inline\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# from matplotlib import rc\n",
    "# # for Arial typefont\n",
    "# matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "## for LaTeX typefont\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "# matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "## for another LaTeX typefont\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.load('/Users/pchourasia1/Desktop/Host_Classification/Data Processing/ALIGNED_sequences.npy',allow_pickle=True)\n",
    "attributes = np.load('/Users/pchourasia1/Desktop/Host_Classification/Data Processing/attributes.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_names = attributes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5558, 5558)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(host_names), len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmers(sequence, ksize):\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - ksize + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + ksize]\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size_val = 3\n",
    "\n",
    "protein_kmers_list = []\n",
    "for protein_kmers in range(len(sequences)):\n",
    "#     print(protein_kmers, \"/\",len(sequences))\n",
    "    k_mers_vals = build_kmers(sequences[protein_kmers],k_size_val)\n",
    "\n",
    "    # str(k_mers_vals[0])\n",
    "    k_mers_list = []\n",
    "    for mers_ind in range(len(k_mers_vals)):\n",
    "        k_mers_list.append(str(k_mers_vals[mers_ind]))\n",
    "        \n",
    "    protein_kmers_list.append(k_mers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'M']\",\n",
       " \"['-' 'M' 'F']\",\n",
       " \"['M' 'F' 'V']\",\n",
       " \"['F' 'V' 'F']\",\n",
       " \"['V' 'F' 'L']\",\n",
       " \"['F' 'L' '-']\",\n",
       " \"['L' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'L']\",\n",
       " \"['V' 'L' 'L']\",\n",
       " \"['L' 'L' 'P']\",\n",
       " \"['L' 'P' 'L']\",\n",
       " \"['P' 'L' '-']\",\n",
       " \"['L' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'S']\",\n",
       " \"['V' 'S' 'S']\",\n",
       " \"['S' 'S' '-']\",\n",
       " \"['S' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'Q']\",\n",
       " \"['-' 'Q' '-']\",\n",
       " \"['Q' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'C']\",\n",
       " \"['-' 'C' '-']\",\n",
       " \"['C' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'N']\",\n",
       " \"['V' 'N' 'L']\",\n",
       " \"['N' 'L' 'T']\",\n",
       " \"['L' 'T' 'T']\",\n",
       " \"['T' 'T' 'R']\",\n",
       " \"['T' 'R' '-']\",\n",
       " \"['R' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'T']\",\n",
       " \"['-' 'T' 'Q']\",\n",
       " \"['T' 'Q' 'L']\",\n",
       " \"['Q' 'L' 'P']\",\n",
       " \"['L' 'P' '-']\",\n",
       " \"['P' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'P']\",\n",
       " \"['-' 'P' 'A']\",\n",
       " \"['P' 'A' 'Y']\",\n",
       " \"['A' 'Y' 'T']\",\n",
       " \"['Y' 'T' 'N']\",\n",
       " \"['T' 'N' 'S']\",\n",
       " \"['N' 'S' '-']\",\n",
       " \"['S' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'F']\",\n",
       " \"['-' 'F' 'T']\",\n",
       " \"['F' 'T' 'R']\",\n",
       " \"['T' 'R' 'G']\",\n",
       " \"['R' 'G' '-']\",\n",
       " \"['G' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'Y']\",\n",
       " \"['V' 'Y' 'Y']\",\n",
       " \"['Y' 'Y' 'P']\",\n",
       " \"['Y' 'P' 'D']\",\n",
       " \"['P' 'D' '-']\",\n",
       " \"['D' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'K']\",\n",
       " \"['-' 'K' 'V']\",\n",
       " \"['K' 'V' 'F']\",\n",
       " \"['V' 'F' '-']\",\n",
       " \"['F' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'R']\",\n",
       " \"['-' 'R' 'S']\",\n",
       " \"['R' 'S' 'S']\",\n",
       " \"['S' 'S' '-']\",\n",
       " \"['S' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' '-']\",\n",
       " \"['V' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'L']\",\n",
       " \"['-' 'L' 'H']\",\n",
       " \"['L' 'H' 'S']\",\n",
       " \"['H' 'S' 'T']\",\n",
       " \"['S' 'T' '-']\",\n",
       " \"['T' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'Q']\",\n",
       " \"['-' 'Q' 'D']\",\n",
       " \"['Q' 'D' 'L']\",\n",
       " \"['D' 'L' 'F']\",\n",
       " \"['L' 'F' 'L']\",\n",
       " \"['F' 'L' '-']\",\n",
       " \"['L' '-' '-']\",\n",
       " \"['-' '-' 'P']\",\n",
       " \"['-' 'P' 'F']\",\n",
       " \"['P' 'F' 'F']\",\n",
       " \"['F' 'F' 'S']\",\n",
       " \"['F' 'S' 'N']\",\n",
       " \"['S' 'N' 'V']\",\n",
       " \"['N' 'V' '-']\",\n",
       " \"['V' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'T']\",\n",
       " \"['-' 'T' 'W']\",\n",
       " \"['T' 'W' 'F']\",\n",
       " \"['W' 'F' 'H']\",\n",
       " \"['F' 'H' 'A']\",\n",
       " \"['H' 'A' '-']\",\n",
       " \"['A' '-' 'I']\",\n",
       " \"['-' 'I' '-']\",\n",
       " \"['I' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'S']\",\n",
       " \"['-' 'S' '-']\",\n",
       " \"['S' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'G']\",\n",
       " \"['-' 'G' 'T']\",\n",
       " \"['G' 'T' 'N']\",\n",
       " \"['T' 'N' 'G']\",\n",
       " \"['N' 'G' 'T']\",\n",
       " \"['G' 'T' '-']\",\n",
       " \"['T' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'K']\",\n",
       " \"['-' 'K' 'R']\",\n",
       " \"['K' 'R' 'F']\",\n",
       " \"['R' 'F' 'D']\",\n",
       " \"['F' 'D' '-']\",\n",
       " \"['D' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'N']\",\n",
       " \"['-' 'N' 'P']\",\n",
       " \"['N' 'P' '-']\",\n",
       " \"['P' '-' 'V']\",\n",
       " \"['-' 'V' 'L']\",\n",
       " \"['V' 'L' 'P']\",\n",
       " \"['L' 'P' 'F']\",\n",
       " \"['P' 'F' 'N']\",\n",
       " \"['F' 'N' 'D']\",\n",
       " \"['N' 'D' 'G']\",\n",
       " \"['D' 'G' 'V']\",\n",
       " \"['G' 'V' 'Y']\",\n",
       " \"['V' 'Y' 'F']\",\n",
       " \"['Y' 'F' 'A']\",\n",
       " \"['F' 'A' 'S']\",\n",
       " \"['A' 'S' '-']\",\n",
       " \"['S' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'T']\",\n",
       " \"['-' 'T' 'E']\",\n",
       " \"['T' 'E' 'K']\",\n",
       " \"['E' 'K' 'S']\",\n",
       " \"['K' 'S' 'N']\",\n",
       " \"['S' 'N' 'I']\",\n",
       " \"['N' 'I' 'I']\",\n",
       " \"['I' 'I' '-']\",\n",
       " \"['I' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'R']\",\n",
       " \"['-' 'R' 'G']\",\n",
       " \"['R' 'G' 'W']\",\n",
       " \"['G' 'W' 'I']\",\n",
       " \"['W' 'I' 'F']\",\n",
       " \"['I' 'F' 'G']\",\n",
       " \"['F' 'G' 'T']\",\n",
       " \"['G' 'T' '-']\",\n",
       " \"['T' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'T']\",\n",
       " \"['-' 'T' 'L']\",\n",
       " \"['T' 'L' '-']\",\n",
       " \"['L' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'D']\",\n",
       " \"['-' 'D' 'S']\",\n",
       " \"['D' 'S' 'K']\",\n",
       " \"['S' 'K' 'T']\",\n",
       " \"['K' 'T' '-']\",\n",
       " \"['T' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'Q']\",\n",
       " \"['-' 'Q' 'S']\",\n",
       " \"['Q' 'S' '-']\",\n",
       " \"['S' '-' 'L']\",\n",
       " \"['-' 'L' 'L']\",\n",
       " \"['L' 'L' '-']\",\n",
       " \"['L' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'I']\",\n",
       " \"['-' 'I' '-']\",\n",
       " \"['I' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'N']\",\n",
       " \"['V' 'N' 'N']\",\n",
       " \"['N' 'N' 'A']\",\n",
       " \"['N' 'A' 'T']\",\n",
       " \"['A' 'T' 'N']\",\n",
       " \"['T' 'N' '-']\",\n",
       " \"['N' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' '-']\",\n",
       " \"['V' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' 'V']\",\n",
       " \"['-' 'V' 'I']\",\n",
       " \"['V' 'I' 'K']\",\n",
       " \"['I' 'K' 'V']\",\n",
       " \"['K' 'V' 'C']\",\n",
       " \"['V' 'C' 'E']\",\n",
       " \"['C' 'E' '-']\",\n",
       " \"['E' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " \"['-' '-' '-']\",\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_kmers_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3496"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_kmers_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_kmers_final = []\n",
    "for i in range(len(protein_kmers_list)):\n",
    "    tmp = protein_kmers_list[i]\n",
    "    tmp_seq = []\n",
    "    for j in range(len(protein_kmers_list[i])):\n",
    "        aa = tmp[j]\n",
    "        aa_lst = str(list(aa))\n",
    "        aa_lst_1 = aa_lst.replace(\",\",\"\")\n",
    "        aa_lst_2 = aa_lst_1.replace(\"[\",\"\")\n",
    "        aa_lst_3 = aa_lst_2.replace(\"\\\"\",\"\")\n",
    "        aa_lst_4 = aa_lst_3.replace(\"]\",\"\")\n",
    "        aa_lst_5 = aa_lst_4.replace(\"'\",\"\")\n",
    "        aa_lst_6 = aa_lst_5.replace(\" \",\"\")\n",
    "        tmp_seq.append(aa_lst_6)\n",
    "    seq_kmers_final.append(tmp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_seq_kmers_final_list = [''.join(c) for c in product('ABCDEFGHIJKLMNPQRSTVWXYZ-', repeat=3)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Frequency Vector from k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5558"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_kmers_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_vector = []\n",
    "#cnt_check2 = 0\n",
    "for ii in range(len(seq_kmers_final)):\n",
    "    seq_tmp = seq_kmers_final[ii]\n",
    "    listofzeros = [0] * len(unique_seq_kmers_final_list)\n",
    "    for j in range(len(seq_tmp)):\n",
    "        ind_tmp = unique_seq_kmers_final_list.index(seq_tmp[j])\n",
    "        listofzeros[ind_tmp] = listofzeros[ind_tmp] + 1\n",
    "    frequency_vector.append(listofzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5558, 3498)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency_vector),len(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hst = list(np.unique(host_names))\n",
    "len(unique_hst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute data preprocessing Done\n"
     ]
    }
   ],
   "source": [
    "int_hosts = []\n",
    "for ind_unique in range(len(host_names)):\n",
    "    variant_tmp = host_names[ind_unique]\n",
    "    ind_tmp = unique_hst.index(variant_tmp)\n",
    "    int_hosts.append(ind_tmp)\n",
    "    \n",
    "print(\"Attribute data preprocessing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(int_hosts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return mean(check)\n",
    "\n",
    "def svm_fun_kernel(X_train,y_train,X_test,y_test,kernel_mat):\n",
    "\n",
    "#     clf = svm.SVC()\n",
    "    clf = svm.SVC(kernel=kernel_mat)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    clf.fit(kernel_mat, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Kernel Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "# In[5]\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Gaussian NB Accuracy:\",NB_acc)\n",
    "\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Precision:\",NB_prec)\n",
    "    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Recall:\",NB_recall)\n",
    "    \n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB F1 weighted:\",NB_f1_weighted)\n",
    "    \n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Gaussian NB F1 macro:\",NB_f1_macro)\n",
    "    \n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Gaussian NB F1 micro:\",NB_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,NB_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Finally for the MLP- Multilayer Perceptron\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"MLP Accuracy:\",MLP_acc)\n",
    "    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Precision:\",MLP_prec)\n",
    "    \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Recall:\",MLP_recall)\n",
    "    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP F1:\",MLP_f1_weighted)\n",
    "    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"MLP F1:\",MLP_f1_macro)\n",
    "    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"MLP F1:\",MLP_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,MLP_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Knn Accuracy:\",knn_acc)\n",
    "    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Precision:\",knn_prec)\n",
    "    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Recall:\",knn_recall)\n",
    "    \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn F1 weighted:\",knn_f1_weighted)\n",
    "    \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Knn F1 macro:\",knn_f1_macro)\n",
    "    \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Knn F1 micro:\",knn_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,knn_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Random Forest Accuracy:\",fr_acc)\n",
    "    \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Precision:\",fr_prec)\n",
    "    \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Recall:\",fr_recall)\n",
    "    \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest F1 weighted:\",fr_f1_weighted)\n",
    "    \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Random Forest F1 macro:\",fr_f1_macro)\n",
    "    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Random Forest F1 micro:\",fr_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,fr_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "    ##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,LR_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,dt_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(frequency_vector)\n",
    "y = np.array(int_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5558, 15625), 5558)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[ 37   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  4 110   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  1   0   0   0   0  91   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  2   0   0   0   0   0   1   0   0   0   2   0   0   0   4   0   0   0\n",
      "    0   0   0   1]\n",
      " [  2   0   0   0   0   0   5   6   0   0  10   0   0   7   5   0   0   0\n",
      "    0   0   0   2]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  2   0   0   0   0   0   1   4   0   0 273   0   0  16  30   0   0   0\n",
      "    0   0   1   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   1\n",
      "    1   0   0   0]\n",
      " [ 20   0   0   0   0   1  18  19   0   0 266   0   0 131  35   0   0   0\n",
      "    0   0  13  39]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   6   0   0\n",
      "    0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7\n",
      "    0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  156   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  5   0   0   0   0   0   1   1   0   0  28   0   0   6  23   0   0   0\n",
      "    0   0   0 231]]\n",
      "NB Class Wise Accuracy :  [1.         0.96491228 0.         1.         0.         0.98913043\n",
      " 0.1        0.16216216 0.         1.         0.83486239 0.\n",
      " 0.5        0.24169742        nan 0.85714286 0.         0.875\n",
      " 0.98734177 0.                nan 0.78305085]\n",
      "NB Time :  9.030980500000624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-20-cec0359551a8>:130: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-20-cec0359551a8>:174: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix MLP : \n",
      " [[ 35   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0]\n",
      " [  3 111   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0  91   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   2   0   0   6   1   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   9   0   0   5   0   0  18   0   0   0   0\n",
      "    1   0   4]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 257   0   0  70   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   5   0   0   0   0   2\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   1   2   1   0   0  89   0   0 444   0   0   0   0\n",
      "    0   0   5]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   6   0   0\n",
      "    0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  156   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   2   0   0   0   0   8   0   0  81   0   0   0   0\n",
      "    0   0 203]]\n",
      "MLP Class Wise Accuracy :  [0.94594595 0.97368421 0.         1.         0.         0.98913043\n",
      " 0.         0.24324324 0.         1.         0.78593272 0.\n",
      " 0.625      0.81918819        nan 0.85714286 0.         1.\n",
      " 0.98734177 0.         0.68813559]\n",
      "MLP Time :  44.981575099999645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN : \n",
      " [[ 33   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0 112   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0  92   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   0   0   0   8   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   6   0   0   7   0   0  17   0   0   0   0\n",
      "    0   5]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0 194   0   0 126   0   0   0   0\n",
      "    0   5]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   6   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   3   0   0  33   0   0 480   0   0   0   0\n",
      "    0  25]\n",
      " [  3   0   0   0   0   0   0   0   0   0   1   0   0   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0\n",
      "    0   0]\n",
      " [  0   4   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0 153\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1   0   0  13   0   0  61   1   0   0   1\n",
      "    0 217]]\n",
      "KNN Class Wise Accuracy :  [0.89189189 0.98245614 0.         1.         0.         1.\n",
      " 0.2        0.16216216 0.         1.         0.59327217 0.\n",
      " 0.75       0.88560886 0.42857143 0.         0.875      0.96835443\n",
      " 0.         0.73559322]\n",
      "KNN Time :  2.4168741999992562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-20-cec0359551a8>:249: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix RF : \n",
      " [[ 36   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0 114   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0  91   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   1   0   0   8   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   2   9   0   0   3   0   0  18   1   0   0   0\n",
      "    0   0   4]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 213   0   0 113   0   0   0   0\n",
      "    0   0   1]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   1   0   0   0   0   0   0   0   0   5   0   0   0   0   1\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   1   2   3   0   0  20   0   0 489   0   0   0   0\n",
      "    0   0  27]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   6   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  157   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   9   0   0  62   0   0   0   0\n",
      "    0   0 223]]\n",
      "RF Class Wise Accuracy :  [0.97297297 1.         1.         1.         0.         0.98913043\n",
      " 0.         0.24324324 0.         1.         0.65137615 0.\n",
      " 0.625      0.90221402        nan 0.85714286 1.         1.\n",
      " 0.99367089 0.         0.7559322 ]\n",
      "RF Time :  17.25233880000087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LR : \n",
      " [[ 34   0   0   0   0   1   0   0   0   0   0   0   0   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0 114   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0  92   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   1   0   0   7   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   9   0   0   4   0   0  20   0   0   0   0\n",
      "    0   2]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 196   0   0 131   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0  21   0   0 492   0   0   0   0\n",
      "    0  27]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   6   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5   0   0  59   1   0   0   0\n",
      "    0 230]]\n",
      "LR Class Wise Accuracy :  [0.91891892 1.         1.         1.         0.         1.\n",
      " 0.2        0.24324324 0.         1.         0.59938838 0.\n",
      " 0.875      0.90774908 0.85714286 1.         1.         0.99367089\n",
      " 0.         0.77966102]\n",
      "LR Time :  48.82639629999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-20-cec0359551a8>:321: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix DT : \n",
      " [[ 33   2   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    1   0   0]\n",
      " [  0 111   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0\n",
      "    1   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0  91   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   2   0   0   7   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   2  10   0   0   4   0   0  17   1   0   0   0\n",
      "    0   0   3]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0   0 204   0   0 118   0   0   0   0\n",
      "    0   0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   4   2   0   0   0   1\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   1   2   6   0   0  26   0   0 483   0   0   0   0\n",
      "    0   0  24]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   6   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  156   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8   0   0  65   0   0   0   1\n",
      "    0   0 221]]\n",
      "DT Class Wise Accuracy :  [0.89189189 0.97368421 1.         1.         0.         0.98913043\n",
      " 0.1        0.27027027 0.         1.         0.62385321 0.\n",
      " 0.5        0.89114391        nan 0.85714286 1.         1.\n",
      " 0.98734177 0.         0.74915254]\n",
      "DT Time :  4.0957877999999255\n",
      "Confusion Matrix SVM : \n",
      " [[ 35   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0]\n",
      " [  0 114   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0  92   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   1   0   0   7   0   1   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0  12   0   0   4   0   0  17   1   0   0   0\n",
      "    0   0   3]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   4   0   0 195   0   0 125   1   0   0   0\n",
      "    0   0   2]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0   0   1\n",
      "    0   0   0]\n",
      " [  0   0   0   1   0   1   2  10   0   0  23   0   0 479   0   0   0   0\n",
      "    0   0  26]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   6   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  156   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   5   0   0  64   0   1   0   0\n",
      "    1   0 222]]\n",
      "SVM Class Wise Accuracy :  [0.94594595 1.         1.         1.         0.         1.\n",
      " 0.1        0.32432432 0.         1.         0.59633028 0.\n",
      " 0.875      0.88376384        nan 0.85714286 1.         1.\n",
      " 0.98734177 0.         0.75254237]\n",
      "SVM Time :  52.38425840000036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pchourasia1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-20-cec0359551a8>:93: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "svm_table.append(svm_return)\n",
    "     \n",
    "svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>F1 (Micro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.822155</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.808048</td>\n",
       "      <td>0.634862</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.826789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.767405</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.643502</td>\n",
       "      <td>0.456650</td>\n",
       "      <td>0.647482</td>\n",
       "      <td>0.735478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.817705</td>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.805352</td>\n",
       "      <td>0.521972</td>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.768650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.799918</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.789556</td>\n",
       "      <td>0.539060</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.754923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.827338</td>\n",
       "      <td>0.835207</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>0.627905</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>0.819153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.824940</td>\n",
       "      <td>0.839693</td>\n",
       "      <td>0.824940</td>\n",
       "      <td>0.817996</td>\n",
       "      <td>0.680405</td>\n",
       "      <td>0.824940</td>\n",
       "      <td>0.828195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.821657</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.808443</td>\n",
       "      <td>0.617808</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.814805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)  F1 (Micro)  \\\n",
       "SVM  0.812950   0.822155  0.812950       0.808048    0.634862    0.812950   \n",
       "NB   0.647482   0.767405  0.647482       0.643502    0.456650    0.647482   \n",
       "MLP  0.810552   0.817705  0.810552       0.805352    0.521972    0.810552   \n",
       "KNN  0.798561   0.799918  0.798561       0.789556    0.539060    0.798561   \n",
       "RF   0.827338   0.835207  0.827338       0.820596    0.627905    0.827338   \n",
       "LR   0.824940   0.839693  0.824940       0.817996    0.680405    0.824940   \n",
       "DT   0.813549   0.821657  0.813549       0.808443    0.617808    0.813549   \n",
       "\n",
       "      ROC AUC  \n",
       "SVM  0.826789  \n",
       "NB   0.735478  \n",
       "MLP  0.768650  \n",
       "KNN  0.754923  \n",
       "RF   0.819153  \n",
       "LR   0.828195  \n",
       "DT   0.814805  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
